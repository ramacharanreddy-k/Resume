\documentclass[11pt,a4paper,sans]{resume}
\usepackage[left=0.2in,top=0.2in,right=0.3in,bottom=0.3in]{geometry}
\usepackage{hyperref}
\usepackage{fontawesome5}
\usepackage{verbatim}
\usepackage{amsmath} 

% Add these lines to reduce space between items and customize bullet points
\usepackage{enumitem}
\setlist[itemize]{noitemsep, topsep=0pt, parsep=0pt, partopsep=0pt, leftmargin=*}
\renewcommand{\labelitemi}{$\bullet$}

% Reduce paragraph spacing
\parskip=0pt

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=black,
    urlcolor=black,
}

\name{Ramacharan Reddy Kasireddy}
\address{
    {\small
    ramachar@buffalo.edu \quad
    +1 716-292-6481 \quad
    www.linkedin.com/in/ramacharanreddy-k/ \quad
    https://github.com/ramacharanreddy-k 
    }
}

\begin{document}
\vspace{0.75em}
\noindent\rule{\linewidth}{0.2pt}
\vspace{0.2em}
An aspiring data scientist with proficiency in Machine Learning and AI and a strong passion for data-driven problem-solving, equipped with expertise in SQL, Python, statistics, data analysis, and data engineering.


\vspace{0.75em}
\begin{rSection}{SKILLS}
\vspace{0.75em}

\begin{tabular}{ @{} >{\bfseries}l @{\hspace{6ex}} l }
Programming: & Python, SQL, R, Java, JavaScript \\
Data Science: & PySpark, MLFlow, Data Visualization, Data Transformation, Data Modelling\\
AI/ML: & ML, Deep Learning, NLP, Scikit-learn, PyTorch, OpenAI, Langchain, LlamaIndex, Pinecone \\
Cloud \& Databases: & Azure, Databricks, AWS (SageMaker, SQS, Lambda, DynamoDB), MongoDB, PostgreSQL \\
CI/CD Frameworks: & Git, GitLab, Jenkins, Docker, Terraform \\
Data Analysis: & Power BI, Pandas, NumPy, Matplotlib, Seaborn, Statistial Time Series Regression Analysis \\
Web Technologies: & HTML5, CSS, Figma, Bootstrap, Fast API, Django, Flask, Streamlit
\end{tabular}
\end{rSection}

\vspace{0.75em}
\begin{rSection}{Certifications}
\vspace{0.75em}

\begin{itemize}
    \item AWS Certified Cloud Practitioner (Amazon Web Services)
\end{itemize}
\end{rSection}

\vspace{0.75em}
\begin{rSection}{WORK EXPERIENCE}
\vspace{0.75em}

{\bf Feuji INC} {\em Data Science and Analytics Intern} \hfill Aug 2024 -- Present \\
\textbf{AI-Powered IVR Automation} [Python, AWS Lambda, AWS Sagemaker, AWS DynamoDB, Langchain, OpenAI, Twilio] \\
\text{As a data science intern I integrated OpenAI \& LangChain to optimize the Interactive Voice Response(IVR) system.}
\vspace{0.75em}
\begin{itemize}
  \item Leveraged \textbf{OpenAI} to fully automate \textbf{IVR path} optimization, eliminating manual updates by \textbf{100\%}.
  \item Optimized Call automation system helped reduce the call duration by \textbf{60\%} across \textbf{200,000+ daily verifications}.
  \item Built scalable, \textbf{serverless solution} with \textbf{AWS Lambda, DynamoDB, SQS} achieving \textbf{99.9\% uptime}.
  \item Adapted industry best practice in \textbf{data governance} using \textbf{AWS KMS} for secure handling of sensitive data.
\end{itemize}

\vspace{0.75em}
{\textbf{MedicalBot}} [Python, LangChain, OpenAI, Pinecone, FastAPI, Streamlit]
\vspace{0.75em}
\begin{itemize}
  \item Designed an advanced \textbf{medical Q\&A system} using \textbf{custom chunking} for document segmentation and \textbf{GPT-4} for context-rich medical transcription summaries, resulting in a \textbf{30\% improvement} in information retrieval accuracy.
  \item Enhanced retrieval precision by \textbf{40\%} by implementing a \textbf{hybrid method} combining \textbf{vector similarity search}, \textbf{TF-IDF keyword matching}, and a \textbf{custom re-ranking algorithm}.
  \item Architected a scalable system with a \textbf{FastAPI backend} and \textbf{Streamlit frontend}, integrating \textbf{LangChain components} for query classification and an \textbf{RAG pipeline}.
\end{itemize}

\vspace{0.75em}
\noindent\rule{\linewidth}{0.4pt}
{\bf Flable AI} {\em Data Science Intern} \hfill Mar 2023 -- Dec 2023\\
{\textbf{Data Insights for Clients}} [Azure, Databricks, Python, Spark, PowerBI, MLflow, Stats models, PostgreSQL, Jenkins]
\vspace{0.75em}
\begin{itemize}
  \item Created \textbf{Python} script for \textbf{traffic analysis}, utilizing \textbf{Scikit-learn} for data preprocessing and feature extraction.
  \item Developed interactive \textbf{PowerBI} reports showcasing user engagement metrics, powered by real-time \textbf{PostgreSQL} data.
  \item Leveraged \textbf{Azure dataflow}, \textbf{Jenkins CI/CD} with automated testing, achieving \textbf{75\% reduction} in processing time.
\end{itemize}

\vspace{0.75em}
{\textbf{Flable Digital Assistant}} [Python, Pandas, ChatGPT, NLP, Telegram Bot, Fast API, PostgreSQL, MongoDB]
\vspace{0.75em}
\begin{itemize}
  \item Led development of the Flable Digital Assistant employing \textbf{Telebot} library, \textbf{ChatGPT}, and internal \textbf{chart builder API}.
  \item Developed user-friendly interface for quick access to \textbf{strategy recommendations}, \textbf{web and business analytics}.
  \item Implemented \textbf{automated data review and reporting}, reducing client's weekly analysis time by up to \textbf{60\%}.
\end{itemize}

\vspace{0.75em}
\noindent\rule{\linewidth}{0.4pt}
{\bf AI Research Assistant} University at Buffalo \hfill Jan 2024 - May 2024 \\
{\textbf{Carbon Emission Reduction Techniques}} [Python, PyTorch, TensorFlow, Scikit-Learn, NumPy, Pandas]\\
During AI research I was able to learn how to achieve energy efficiency while maintaining the LLM's performance.
\vspace{0.75em}
\begin{itemize}
  \item Researched GPT-2's \textbf{energy efficiency} \& \textbf{carbon reduction} using \textbf{quantization}, \textbf{distillation}, \textbf{low-rank factorization}.
  \item Optimized GPT-2 efficiency: \textbf{19.8\% CO2 reduction} with only \textbf{6\% perplexity increase} via quantization.
  \item Achieved \textbf{45.2\% emissions reduction} combining distillation and quantization, demonstrating significant carbon savings at the cost of substantial performance degradation by \textbf{57.4\%}, suitable for extreme efficiency scenarios.
\end{itemize}
\end{rSection}

\vspace{0.75em}
\begin{rSection}{EDUCATION}
\vspace{0.75em}
{\bf University at Buffalo, The State University of New York} \hfill Buffalo, New York \\
Master of Science, Computer Science, CGPA: 3.7/4 \hfill 2023 -- Present \\
{\em Coursework: Data Intensive Computing, Computer Vision, Machine Learning, Deep Learning}

\vspace{0.75em}
{\bf Vellore Institute of Technology} \hfill Chennai, India \\
Bachelor of Technology, Computer Science and Engineering, CGPA: 8.42/10 \hfill July 2019 -- May 2023 \\
{\em Coursework: Data Analytics, Data Visualization, Natural Language Processing, Artificial Intelligence}
\end{rSection}

\vspace{0.75em}
\begin{rSection}{ACADEMIC PROJECTS}
\vspace{0.75em}
\vspace{0.75em}
{\textbf{Mathematical Formula to LaTeX Code Conversion}} [Python, PyTorch, Vision Transformers]
\begin{itemize}
  \item Engineered a \textbf{deep learning system} utilizing \textbf{Vision Transformer architecture} to convert images containing mathematical formulas into LaTeX code, achieving a \textbf{BLEU score of 0.72} on the Im2LaTeX dataset.
\end{itemize}

\vspace{0.75em}
{\textbf{Company Bankruptcy Prediction}} [Python, Pandas, NumPy, Seaborn, Scikit-Learn, Jupyter Notebook]
\begin{itemize}
  \item Developed machine learning model for bankruptcy prediction, utilized \textbf{SMOTE} for oversampling to address \textbf{data-imbalance}.
  \item Applied ensemble methods (\textbf{logistic regression}, \textbf{random forest}, \textbf{XGBoost}), achieving \textbf{82.04\% accuracy}.
  \item Utilized \textbf{CatBoost} to identify and visualize top 20 influential features, enhancing model interpretability.
\end{itemize}
\end{rSection}
\end{document}